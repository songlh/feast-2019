\section{Experiment}

\subsection{Methodology}

\noindent\textbf{Implementation and Platform.} 
We implement \Tool{} using LLVM-7.0.0~\cite{LLVM}, 
and conduct our experiments on a Linux machine, 
with E5-2630 CPU, 32GB memory and 3.10 kernel. 

\noindent\textbf{Benchmarks.}
\Tool{} is a tool to automatically extract FSMs implemented in programs. 
Since we build \Tool{} using LLVM, 
our current implementation can only work on C/C++ programs.  
However, we believe that our algorithm is general enough 
to be extended to other programming languages. 

To evaluate \Tool{}, we collect C/C++ programs from three sources. 
First, we evaluate \Tool{} on two programs collected in a CTF contest~\cite{ctf}, 
one contains a FSM, and the other one does not. 
Second, we leverage the DARPA CGC dataset~\cite{CGC}. 
In total, there are 200 programs in the CGC dataset.
As discussed in Section~\ref{sec:study}, 
we already use 40 of them to conduct our empirical study,
so that we use the remaining 160 programs in our evaluation.
Third, we apply \Tool{} to OpenVPN~\cite{openvpn}, 
which provides an implementation of virtual private network and 
is included in software packages of every released Linux version. 



\noindent\textbf{Evaluation Setting}


We mainly compute metrics to answer two research questions regarding the coverage and accuracy of \Tool{}.

\textbf{Q1.} Whether \Tool{} can identify all FSM implementations in evaluated software?
 
\textbf{Q2.} Whether \Tool{} will report loops, which are not to implement FSMs, 
generating false positives. 

