\section{Experiment}

\subsection{Methodology}

\noindent\textbf{Implementation and Platform.} 
We implement \Tool{} using LLVM-7.0.0~\cite{LLVM}, 
and conduct our experiments on a Linux machine, 
with E5-2630 CPU, 32GB memory and 3.10 kernel. 

\noindent\textbf{Benchmarks.}
\Tool{} is a tool to automatically extract FSMs implemented in a program. 
Since we build \Tool{} using LLVM, 
our current implementation can only work on C/C++ programs.  
However, we believe that our algorithm is general enough 
to be extended to other programming languages. 


To evaluate \Tool{}, we collect C/C++ programs from three sources. 
First, we evaluate \Tool{} on two programs collected in a CTF contest~\cite{ctf}, 
one contains a FSM, and the other one does not. 
Second, we leverage the DARPA CGC dataset~\cite{CGC}. 
In total, there are 200 programs in the CGC dataset.
As discussed in Section~\ref{sec:study}, 
we already use 40 of them to conduct our empirical study,
so that we use the remaining 160 programs in our evaluation.
Third, we apply \Tool{} to OpenVPN~\cite{openvpn}, 
which provides an implementation of virtual private network and 
is included in software packages of every released Linux version. 

\input{section/tab-app}

The benchmark information is shown in Table~\ref{tab:benchmark}.
In total, we use 163 different programs to evaluate \Tool{}.
All our benchmarks are either real software or 
simplified programs from real applications. 
They are either widely-used in the real world or popular in the security community. 
They cover programs in small, medium and large sizes, 
with lines of code ranging from 0.3 thousand to more than 100 thousand.  
We believe that our benchmarks are representative 
enough to evaluate the effectiveness of \Tool{}.

\noindent\textbf{Evaluation Setting.} 
For all our benchmark programs, we manually examine all their loops and 
identify all FSM loops. 
As shown in Table~\ref{tab:benchmark}, there are in 
total 66 FSMs.
Four FSM loops contain two state variables, 
and all other FMS loops contain exact one state variables.
Therefore, there are in total 70 FSMs implemented in all our benchmarks.  
We apply \Tool{} to all benchmark programs. 
We mainly compute metrics to answer two research 
questions regarding the coverage and accuracy of \Tool{}.


\textbf{Q1. Coverage:} whether \Tool{} can identify all implemented FSMs?
 
\textbf{Q2. Accuracy:} whether \Tool{} will report loops, which are FSM loops, 
generating false positives. 


\subsection{Experimental Results}

\input{section/tab-exp}

\noindent\textbf{Coverage.}


\noindent\textbf{Accuracy.}